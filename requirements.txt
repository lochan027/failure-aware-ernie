# Failure-Aware ERNIE Requirements

# Core ML Framework
torch>=2.0.0
transformers>=4.35.0

# LLaMA-Factory for fine-tuning
# Install from source: pip install git+https://github.com/hiyouga/LLaMA-Factory.git
# Or use: llamafactory[torch,metrics]

# Dataset handling
datasets>=2.14.0

# Evaluation and metrics
numpy>=1.24.0
scikit-learn>=1.3.0
tqdm>=4.65.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# Configuration
pyyaml>=6.0

# PEFT for efficient fine-tuning
peft>=0.6.0

# Accelerate for distributed training
accelerate>=0.24.0

# Optional: for better performance
bitsandbytes>=0.41.0  # for 8-bit training
deepspeed>=0.12.0     # for distributed training
tensorboard>=2.14.0   # for training visualization

# Development
pytest>=7.4.0
black>=23.0.0
flake8>=6.1.0
